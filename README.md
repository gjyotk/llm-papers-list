# llm-papers

## Overview

Every week, I set out to read, reflect on, and document my learnings from one LLM-based research paper. This repository is a personal effort to stay connected with the latest developments, deepen my understanding of Machine Learning, and share my insights with others who share this passion. 

## Papers List

Below is the list of most relevant foundational papers on LLMs (according to me) that I've curated from Latent Space's 2025 Papers [list](https://www.latent.space/p/2025-papers#%C2%A7section-frontier-llms) and suggested reading materials from the course "Generative AI with Large Language Models" by Deeplearning.ai on Coursera:


1. **[Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)** by *Alec Radford et al., 2018*
   - [Paper Notes](https://www.dropbox.com/scl/fi/d6p85rjw5ccs1521a0sat/language_understanding_paper.pdf?rlkey=plnwzmzmrqijzcjt1je9im0zw&st=7cuzqrp7&dl=0)
   - Summary:
   - Key Contributions:
   - Challenges the Paper Solves:
   - Personal Insights/Takeaways:

3. **[Attention is All You Need](https://arxiv.org/abs/1706.03762)** by *Ashish Vaswani et al., 2017*


## How to Use This Repository

You can follow my progress by checking the updates in this README or visiting [this](gjyotk.github.io/llm-papers-list/#/) URL . Feel free to share your thoughts, suggest additional papers, or discuss the content via GitHub issues or pull requests.

Stay tuned for weekly updates!


